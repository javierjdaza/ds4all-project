{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data Processing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split,cross_validate,GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder,MinMaxScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "# Get variable names\n",
    "# from varname import nameof\n",
    "\n",
    "# Pipeline diagram\n",
    "from sklearn import set_config\n",
    "\n",
    "# MODELS\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ausencias = pd.read_csv('./data/raw/Ausencias.csv')\n",
    "definitivas = pd.read_csv('./data/raw/Definitivas_asignaturas.csv')\n",
    "estudiantes = pd.read_csv('./data/raw/Listado_estudiantes.csv')\n",
    "psat = pd.read_csv('./data/raw/Pruebas_PSAT.csv')\n",
    "saber_11 = pd.read_csv('./data/raw/Pruebas_Saber_11.csv')\n",
    "simulacro = pd.read_csv('./data/raw/Simulacro_pruebas_saber_11.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "saber_11 = saber_11.pivot_table(index=['codigo','anio_escolar'], columns=['asignatura'],values='resultado').reset_index()\n",
    "saber_11 = saber_11.rename_axis(None, axis=1)\n",
    "saber_11.columns = [f'{j.lower().replace(\"\",\"ni\").replace(\" \",\"_\").strip()}_saber_11'  for j in saber_11.columns ]\n",
    "saber_11.rename(columns={f'codigo_saber_11':'codigo'}, inplace= True)\n",
    "del saber_11['anio_escolar_saber_11']\n",
    "del saber_11['global_saber_11']\n",
    "saber_11_materias = [ j for j in saber_11.columns if j.endswith('saber_11') ]\n",
    "for i in saber_11_materias:\n",
    "    if i == 'ingles_saber_11':\n",
    "        saber_11[i] = saber_11[i].apply(lambda x: 1 if x >=80 else 0)\n",
    "    else:\n",
    "        saber_11[i] = saber_11[i].apply(lambda x: 1 if x >=60 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "psat = psat.pivot_table(index=['codigo','anio_escolar'], columns=['asignatura'],values='resultado').reset_index()\n",
    "psat.drop_duplicates(subset= 'codigo', keep= 'first', inplace = True)\n",
    "psat = psat.rename_axis(None, axis=1)\n",
    "psat.columns = [f'{j.lower().replace(\" \",\"_\").strip()}_psat'  for j in psat.columns ]\n",
    "psat.rename(columns={f'codigo_psat':'codigo'}, inplace= True)\n",
    "del psat['anio_escolar_psat']\n",
    "del psat['combinado_psat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitivas_10 = definitivas[definitivas.grado == 10]\n",
    "definitivas_10 = definitivas_10.groupby(['codigo','asignatura'])['resultado'].mean().to_frame().reset_index()\n",
    "definitivas_10 = definitivas_10.pivot_table(index=['codigo'], columns=['asignatura'],values='resultado').reset_index()\n",
    "definitivas_10 = definitivas_10.rename_axis(None, axis=1)\n",
    "definitivas_10.columns = [f'{j.lower().replace(\" \",\"_\").replace(\"\",\"ni\").strip()}_notas_10'  for j in definitivas_10.columns ]\n",
    "definitivas_10.rename(columns={f'codigo_notas_10':'codigo'}, inplace= True)\n",
    "\n",
    "definitivas_11 = definitivas[definitivas.grado == 11]\n",
    "definitivas_11 = definitivas_11.groupby(['codigo','asignatura'])['resultado'].mean().to_frame().reset_index()\n",
    "definitivas_11 = definitivas_11.pivot_table(index=['codigo'], columns=['asignatura'],values='resultado').reset_index()\n",
    "definitivas_11 = definitivas_11.rename_axis(None, axis=1)\n",
    "definitivas_11.columns = [f'{j.lower().replace(\" \",\"_\").replace(\"\",\"ni\").strip()}_notas_11'  for j in definitivas_11.columns ]\n",
    "definitivas_11.rename(columns={f'codigo_notas_11':'codigo'}, inplace= True)\n",
    "\n",
    "definitivas_12 = definitivas[definitivas.grado == 12]\n",
    "definitivas_12 = definitivas_12.groupby(['codigo','asignatura'])['resultado'].mean().to_frame().reset_index()\n",
    "definitivas_12 = definitivas_12.pivot_table(index=['codigo'], columns=['asignatura'],values='resultado').reset_index()\n",
    "definitivas_12 = definitivas_12.rename_axis(None, axis=1)\n",
    "definitivas_12.columns = [f'{j.lower().replace(\" \",\"_\").replace(\"\",\"ni\").strip()}_notas_12'  for j in definitivas_12.columns ]\n",
    "definitivas_12.rename(columns={f'codigo_notas_12':'codigo'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12    10829\n",
      "11     6694\n",
      "Name: grado, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(simulacro.grado.value_counts())\n",
    "simulacro['resultado'] = simulacro['resultado'].apply(lambda x: str(x).strip().replace(',','.'))\n",
    "simulacro['resultado'] = simulacro['resultado'].apply(lambda x: float(x))\n",
    "\n",
    "\n",
    "simulacro_11 = simulacro[simulacro.grado == 11]\n",
    "simulacro_11 = simulacro_11.groupby(['codigo','asignatura'])['resultado'].mean().to_frame().reset_index()\n",
    "simulacro_11 = simulacro_11.pivot_table(index=['codigo'], columns=['asignatura'],values='resultado').reset_index()\n",
    "simulacro_11 = simulacro_11.rename_axis(None, axis=1)\n",
    "simulacro_11.columns = [f'{j.lower().replace(\" \",\"_\").replace(\"\",\"ni\").strip()}_sim_11'  for j in simulacro_11.columns ]\n",
    "simulacro_11.rename(columns={f'codigo_sim_11':'codigo'}, inplace= True)\n",
    "del simulacro_11['def_sim_11']\n",
    "\n",
    "simulacro_12 = simulacro[simulacro.grado == 12]\n",
    "simulacro_12 = simulacro_12.groupby(['codigo','asignatura'])['resultado'].mean().to_frame().reset_index()\n",
    "simulacro_12 = simulacro_12.pivot_table(index=['codigo'], columns=['asignatura'],values='resultado').reset_index()\n",
    "simulacro_12 = simulacro_12.rename_axis(None, axis=1)\n",
    "simulacro_12.columns = [f'{j.lower().replace(\" \",\"_\").replace(\"\",\"ni\").strip()}_sim_12'  for j in simulacro_12.columns ]\n",
    "simulacro_12.rename(columns={f'codigo_sim_12':'codigo'}, inplace= True)\n",
    "del simulacro_12['def_sim_12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10 = definitivas_10.merge(saber_11, on = 'codigo', how = 'inner')\n",
    "df_10 = df_10.merge(psat, on = 'codigo', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11 = definitivas_11.merge(saber_11, on = 'codigo', how = 'inner')\n",
    "df_11 = df_11.merge(simulacro_11, on = 'codigo', how = 'inner')\n",
    "del df_11['ciencias_sociales_notas_11']\n",
    "df_11.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12 = definitivas_12.merge(saber_11, on = 'codigo', how = 'inner')\n",
    "df_12 = df_12.merge(simulacro_12, on = 'codigo', how = 'inner')\n",
    "df_12.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_materia_saber(df:pd.DataFrame,materia:str)->pd.DataFrame:\n",
    "    \"\"\"Get Rid all the saber 11 values, and just keep the \"materia\" result of the parameter\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe with all the columns (all saber 11 scores)\n",
    "        materia (str): the name of the target\n",
    "\n",
    "    Returns:\n",
    "        (pd.DataFrame): the dataframe transformed with target value corresponding to the \"materia\" saber 11\n",
    "    \"\"\"\n",
    "    col_add = df[[materia]].copy()\n",
    "    columns = [ i for i in df.columns if not i.endswith('saber_11') ]\n",
    "    df = df[columns]\n",
    "    df[materia] = col_add\n",
    "\n",
    "    return df\n",
    "\n",
    "math_column = 'matematicas_saber_11'\n",
    "lectura_column = 'lectura_critica_saber_11'\n",
    "ingles_column = 'ingles_saber_11'\n",
    "ciencias_column = 'ciencias_saber_11'\n",
    "sociales_column = 'sociales_y_ciudadanas_saber_11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matematicas\n",
    "\n",
    "df_10_MATH = keep_materia_saber(df_10,math_column)\n",
    "df_11_MATH = keep_materia_saber(df_11,math_column)\n",
    "df_12_MATH = keep_materia_saber(df_12,math_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lectura\n",
    "df_10_LECT = keep_materia_saber(df_10,lectura_column)\n",
    "df_11_LECT = keep_materia_saber(df_11,lectura_column)\n",
    "df_12_LECT = keep_materia_saber(df_12,lectura_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingles\n",
    "df_10_INGLES= keep_materia_saber(df_10,ingles_column)\n",
    "df_11_INGLES= keep_materia_saber(df_11,ingles_column)\n",
    "df_12_INGLES= keep_materia_saber(df_12,ingles_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ciencias_column\n",
    "df_10_CIENCIAS = keep_materia_saber(df_10,ciencias_column)\n",
    "df_11_CIENCIAS = keep_materia_saber(df_11,ciencias_column)\n",
    "df_12_CIENCIAS = keep_materia_saber(df_12,ciencias_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sociales_column\n",
    "df_10_SOCIALES = keep_materia_saber(df_10,sociales_column)\n",
    "df_11_SOCIALES = keep_materia_saber(df_11,sociales_column)\n",
    "df_12_SOCIALES = keep_materia_saber(df_12,sociales_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['codigo', 'ciencias_sociales_notas_12', 'disciplina_notas_12',\n",
       "       'economia_notas_12', 'espaniol_notas_12', 'estadistica_notas_12',\n",
       "       'filosofia_notas_12', 'fisica_notas_12', 'ingles_notas_12',\n",
       "       'matematicas_notas_12', 'quimica_notas_12', 'biologia_sim_12',\n",
       "       'cts_sim_12', 'competencias_ciudadanas_sim_12', 'fisica_sim_12',\n",
       "       'ingles_sim_12', 'lectura_critica_sim_12', 'matematicas_(espec)_sim_12',\n",
       "       'matematicas_(cuant)_sim_12', 'quimica_sim_12', 'sociales_sim_12',\n",
       "       'sociales_y_ciudadanas_saber_11'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_12_SOCIALES.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_test, y_predict, title = 'Confusion Matrix'):\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    precision = precision_score(y_test, y_predict)\n",
    "    recall = recall_score(y_test, y_predict)\n",
    "    accuracy = accuracy_score(y_test,y_predict)\n",
    "    f1 = f1_score(y_test,y_predict)\n",
    "    roc = roc_auc_score(y_test, y_predict)\n",
    "    metrics = {'Accuracy':accuracy,\n",
    "                'precision':precision,\n",
    "                'Recall':recall,\n",
    "                'f1':f1,\n",
    "                'roc' : roc\n",
    "                 }\n",
    "\n",
    "    metrics_df = pd.DataFrame([metrics])\n",
    "    # print('Recall: ', recall)\n",
    "    # print('Accuracy: ', accuracy)\n",
    "    # print('Precision: ', precision)\n",
    "    # print('F1: ', f1)\n",
    "    display(metrics_df)\n",
    "    sns.heatmap(cm,  cmap= 'Blues', annot=True, fmt='g', annot_kws=    {'size':20})\n",
    "    plt.xlabel('predicted', fontsize=18)\n",
    "    plt.ylabel('actual', fontsize=18)\n",
    "    plt.title(title, fontsize=18)\n",
    "    \n",
    "    plt.show();\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict = {\n",
    "    'df_10_MATH' : 'df_10_MATH',\n",
    "    'df_10_LECT' : 'df_10_LECT',\n",
    "    'df_10_INGLES' : 'df_10_INGLES',\n",
    "    'df_10_CIENCIAS' : 'df_10_CIENCIAS',\n",
    "    'df_10_SOCIALES' : 'df_10_SOCIALES',\n",
    "    'df_11_MATH' : 'df_11_MATH',\n",
    "    'df_11_LECT' : 'df_11_LECT',\n",
    "    'df_11_INGLES' : 'df_11_INGLES',\n",
    "    'df_11_CIENCIAS' : 'df_11_CIENCIAS',\n",
    "    'df_11_SOCIALES' : 'df_11_SOCIALES',\n",
    "    'df_12_MATH' : 'df_12_MATH',\n",
    "    'df_12_LECT' : 'df_12_LECT',\n",
    "    'df_12_INGLES' : 'df_12_INGLES',\n",
    "    'df_12_CIENCIAS' : 'df_12_CIENCIAS',\n",
    "    'df_12_SOCIALES' : 'df_12_SOCIALES',\n",
    "    }\n",
    "\n",
    "dataframes = [df_10_MATH,df_10_LECT,df_10_INGLES,df_10_CIENCIAS,df_10_SOCIALES,\n",
    "df_11_MATH,df_11_LECT,df_11_INGLES,df_11_CIENCIAS,df_11_SOCIALES,\n",
    "df_12_MATH,df_12_LECT,df_12_INGLES,df_12_CIENCIAS,df_12_SOCIALES]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets_models_dict = {\n",
    "    'df_10_MATH': 'knn_classifier',\n",
    "    'df_10_LECT': 'knn_classifier',\n",
    "    'df_10_INGLES': 'knn_classifier',\n",
    "    'df_10_CIENCIAS' : 'gb_classifier',\n",
    "    'df_10_SOCIALES' : 'gb_classifier',\n",
    "    'df_11_MATH': 'knn_classifier',\n",
    "    'df_11_LECT' : 'rf_classifier',\n",
    "    'df_11_INGLES' : 'rf_classifier',\n",
    "    'df_11_CIENCIAS' : 'gb_classifier',\n",
    "    'df_11_SOCIALES': 'knn_classifier',\n",
    "    'df_12_MATH' : 'rf_classifier',\n",
    "    'df_12_LECT' : 'rf_classifier',\n",
    "    'df_12_INGLES' : 'rf_classifier',\n",
    "    'df_12_CIENCIAS' : 'rf_classifier',\n",
    "    'df_12_SOCIALES' : 'gb_classifier',}\n",
    "\n",
    "contador = 0\n",
    "logs_metrics = pd.DataFrame()\n",
    "for i in dataframes:\n",
    "    del i['codigo']\n",
    "    X = i.drop(columns = i.columns[-1], axis = 1)\n",
    "    y = i[f'{i.columns[-1]}']\n",
    "    X_train, X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "    model_choose = datasets_models_dict[list(datasets_models_dict.keys())[contador]]\n",
    "    dataset_name = list(datasets_models_dict.keys())[contador]\n",
    "    if model_choose == 'knn_classifier':\n",
    "\n",
    "        model = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "    elif model_choose == 'rf_classifier':\n",
    "\n",
    "        model = RandomForestClassifier()\n",
    " \n",
    "      \n",
    "    elif model_choose == 'gb_classifier':\n",
    "\n",
    "        model = GradientBoostingClassifier()\n",
    "        \n",
    "\n",
    "    # Build the pipeline\n",
    "    \n",
    "   \n",
    "    # Build the pipeline\n",
    "    pipeline = Pipeline([\n",
    "                    # ('Smote', SMOTE(random_state=0)),\n",
    "                    ('Model', model)\n",
    "                ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train);\n",
    "    y_predict = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:,1]\n",
    "    print(list(datasets_models_dict.keys())[contador])\n",
    "    logs_metrics_ = evaluation(y_test, y_predict)\n",
    "    logs_metrics_['data_Set'] = list(datasets_models_dict.keys())[contador]\n",
    "    logs_metrics = logs_metrics.append(logs_metrics_)\n",
    "    dataset_name_joblib = dataset_name.replace('df_','')\n",
    "    joblib.dump(pipeline,f'./models/{dataset_name_joblib}_{model_choose}.joblib')\n",
    "    print('-'*50)\n",
    "    contador +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# FINALIZE DE MODELS\n",
    "\n",
    "datasets_models_dict = {\n",
    "    'df_10_MATH': 'knn_classifier',\n",
    "    'df_10_LECT': 'knn_classifier',\n",
    "    'df_10_INGLES': 'knn_classifier',\n",
    "    'df_10_CIENCIAS' : 'gb_classifier',\n",
    "    'df_10_SOCIALES' : 'gb_classifier',\n",
    "    'df_11_MATH': 'knn_classifier',\n",
    "    'df_11_LECT' : 'rf_classifier',\n",
    "    'df_11_INGLES' : 'rf_classifier',\n",
    "    'df_11_CIENCIAS' : 'gb_classifier',\n",
    "    'df_11_SOCIALES': 'knn_classifier',\n",
    "    'df_12_MATH' : 'rf_classifier',\n",
    "    'df_12_LECT' : 'rf_classifier',\n",
    "    'df_12_INGLES' : 'rf_classifier',\n",
    "    'df_12_CIENCIAS' : 'rf_classifier',\n",
    "    'df_12_SOCIALES' : 'gb_classifier',}\n",
    "\n",
    "contador = 0\n",
    "logs_metrics = pd.DataFrame()\n",
    "for i in dataframes:\n",
    "    try:\n",
    "        del i['codigo']\n",
    "    except:\n",
    "        pass\n",
    "    X = i.drop(columns = i.columns[-1], axis = 1)\n",
    "    y = i[f'{i.columns[-1]}']\n",
    "    # X_train, X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "    model_choose = datasets_models_dict[list(datasets_models_dict.keys())[contador]]\n",
    "    dataset_name = list(datasets_models_dict.keys())[contador]\n",
    "    if model_choose == 'knn_classifier':\n",
    "\n",
    "        model = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "    elif model_choose == 'rf_classifier':\n",
    "\n",
    "        model = RandomForestClassifier()\n",
    " \n",
    "      \n",
    "    elif model_choose == 'gb_classifier':\n",
    "\n",
    "        model = GradientBoostingClassifier()\n",
    "        \n",
    "\n",
    "    # Build the pipeline\n",
    "    \n",
    "   \n",
    "    # Build the pipeline\n",
    "    pipeline = Pipeline([\n",
    "                    # ('Smote', SMOTE(random_state=0)),\n",
    "                    ('Model', model)\n",
    "                ])\n",
    "    \n",
    "    pipeline.fit(X, y);\n",
    "    # y_predict = pipeline.predict(X_test)\n",
    "    # y_pred_proba = pipeline.predict_proba(X_test)[:,1]\n",
    "    # print(list(datasets_models_dict.keys())[contador])\n",
    "    # logs_metrics_ = evaluation(y_test, y_predict)\n",
    "    # logs_metrics_['data_Set'] = list(datasets_models_dict.keys())[contador]\n",
    "    # logs_metrics = logs_metrics.append(logs_metrics_)\n",
    "    dataset_name_joblib = dataset_name.replace('df_','')\n",
    "    joblib.dump(pipeline,f'./models/{dataset_name_joblib}_{model_choose}.joblib')\n",
    "    print('-'*50)\n",
    "    contador +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f4adde32c9f800d49dd1d1fc6957d6f7973ab66aa2724a2651d03a1be5fdd27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
